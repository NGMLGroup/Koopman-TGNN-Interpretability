{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mgphy\\anaconda3\\envs\\koopman\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\mgphy\\anaconda3\\envs\\koopman\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "# import scipy\n",
    "# import umap\n",
    "import random\n",
    "# import itertools\n",
    "import tsl\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tsl.datasets import PvUS\n",
    "from tsl.data.datamodule import SpatioTemporalDataModule, TemporalSplitter\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "from tsl.metrics.torch import MaskedMAE\n",
    "from tsl.engines import Predictor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from einops import rearrange\n",
    "\n",
    "# from dataset.NCI1_dataset import NCI1\n",
    "# from tqdm import trange\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.DynGraphESN import DynGESNModel\n",
    "\n",
    "from DMD.dmd import KANN\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for more datasets:\n",
    "\n",
    "https://github.com/dtortorella/dyngraphesn/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PvUS-west(length=52560, n_nodes=1082, n_channels=1)\n",
      "Default similarity: distance\n",
      "Available similarity options: {'correntropy', 'distance'}\n"
     ]
    }
   ],
   "source": [
    "dataset = PvUS(root=\"/dataset\", zones=['west'])\n",
    "print(dataset)\n",
    "\n",
    "print(f\"Default similarity: {dataset.similarity_score}\")\n",
    "print(f\"Available similarity options: {dataset.similarity_options}\")\n",
    "\n",
    "sim = dataset.get_similarity(\"distance\")  # or dataset.compute_similarity()\n",
    "\n",
    "connectivity = dataset.get_connectivity(threshold=0.1,\n",
    "                                        include_self=False,\n",
    "                                        normalize_axis=1,\n",
    "                                        layout=\"edge_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataset(n_samples=52473, n_nodes=1082, n_channels=1)\n"
     ]
    }
   ],
   "source": [
    "horizon = 24\n",
    "\n",
    "torch_dataset = tsl.data.SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      connectivity=connectivity,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=horizon,\n",
    "                                      window=64,\n",
    "                                      stride=1)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(\n",
      "  input=(x=[t=64, n=1082, f=1], edge_index=[2, e=124778], edge_weight=[e=124778]),\n",
      "  target=(y=[t=24, n=1082, f=1]),\n",
      "  has_mask=False\n",
      ")\n",
      "{'x': 't n f', 'edge_index': '2 e', 'edge_weight': 'e', 'y': 't n f'}\n"
     ]
    }
   ],
   "source": [
    "sample = torch_dataset[0].to(device)\n",
    "print(sample)\n",
    "print(sample.pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=37718, val_len=4133, test_len=10494, scalers=[target], batch_size=1)\n"
     ]
    }
   ],
   "source": [
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval, num_nodes, feat_size = sample.input.x.shape\n",
    "\n",
    "model = DynGESNModel(input_size=feat_size,\n",
    "                reservoir_size=100,\n",
    "                input_scaling=1.,\n",
    "                reservoir_layers=1,\n",
    "                leaking_rate=0.9,\n",
    "                spectral_radius=0.9,\n",
    "                density=0.5,\n",
    "                reservoir_activation='tanh',\n",
    "                alpha_decay=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageView(x=[64, 1082, 1], edge_index=[2, 124778], edge_weight=[124778])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1082, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample.input.x.unsqueeze(dim=0), sample.input.edge_index, sample.input.edge_weight).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(pl.LightningModule):\n",
    "    def __init__(self, encoder, input_size, output_size, horizon):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.encoder = encoder\n",
    "        self.linear = nn.Linear(input_size, output_size*horizon)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        z = self.encoder(x, edge_index, edge_weight)\n",
    "        b, t, n, f = z.shape\n",
    "        z = rearrange(z, 'b t n f -> b n (t f)', t=t, n=n)\n",
    "        new_x = self.linear(z)\n",
    "        new_x = rearrange(new_x, 'b n (t f) -> b t n f', t=horizon, n=n, f=self.output_size)\n",
    "\n",
    "        return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = LinearRegression(model, input_size=100*time_interval, output_size=feat_size, horizon=horizon).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE        | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | LinearRegression | 163 K \n",
      "---------------------------------------------------\n",
      "153 K     Trainable params\n",
      "10.2 K    Non-trainable params\n",
      "163 K     Total params\n",
      "0.655     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mgphy\\anaconda3\\envs\\koopman\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "Only args ['x', 'edge_weight', 'edge_index'] are forwarded to the model (LinearRegression). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mgphy\\anaconda3\\envs\\koopman\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 100/100 [00:03<00:00, 30.82it/s, v_num=17, val_mae=27.90, train_mae=27.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mgphy\\anaconda3\\envs\\koopman\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mae': MaskedMAE()}\n",
    "\n",
    "# setup predictor\n",
    "predictor = Predictor(\n",
    "    model=forecaster,              # our initialized model\n",
    "    optim_class=torch.optim.Adam,  # specify optimizer to be used...\n",
    "    optim_kwargs={'lr': 0.001},    # ...and parameters for its initialization\n",
    "    loss_fn=loss_fn,               # which loss function to be used\n",
    "    metrics=metrics                # metrics to be logged during train/val/test\n",
    ")\n",
    "\n",
    "# logger = TensorBoardLogger(save_dir=\"logs\", name=\"dynGESN\", version=0)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "                    #  logger=logger,\n",
    "                     devices=1, \n",
    "                     accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                     limit_train_batches=100,  # end an epoch after 100 updates\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(predictor, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sistemare la gestione delle batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
