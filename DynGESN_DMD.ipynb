{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mgphy\\Anaconda3\\envs\\koopman\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import scipy\n",
    "# import umap\n",
    "import random\n",
    "# import itertools\n",
    "import tsl\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tsl.datasets import PvUS\n",
    "from tsl.data.datamodule import SpatioTemporalDataModule, TemporalSplitter\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "\n",
    "# from dataset.NCI1_dataset import NCI1\n",
    "# from tqdm import trange\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.DynGraphESN import DynGESNModel\n",
    "\n",
    "from DMD.dmd import KANN\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for datasets:\n",
    "\n",
    "https://github.com/dtortorella/dyngraphesn/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PvUS(root=\"/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PvUS(length=52560, n_nodes=5016, n_channels=1)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default similarity: distance\n",
      "Available similarity options: {'distance', 'correntropy'}\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default similarity: {dataset.similarity_score}\")\n",
    "print(f\"Available similarity options: {dataset.similarity_options}\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "sim = dataset.get_similarity(\"distance\")  # or dataset.compute_similarity()\n",
    "\n",
    "# print(\"Similarity matrix W:\")\n",
    "# pd.DataFrame(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity = dataset.get_connectivity(threshold=0.1,\n",
    "                                        include_self=False,\n",
    "                                        normalize_axis=1,\n",
    "                                        layout=\"edge_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index (2, 1090660):\n",
      " [[   0    0    0 ... 5015 5015 5015]\n",
      " [   2    3    6 ... 3025 3032 5009]]\n",
      "edge_weight (1090660,):\n",
      " [0.00104493 0.00537338 0.00241709 ... 0.02544574 0.02086223 0.05187358]\n"
     ]
    }
   ],
   "source": [
    "edge_index, edge_weight = connectivity\n",
    "\n",
    "print(f'edge_index {edge_index.shape}:\\n', edge_index)\n",
    "print(f'edge_weight {edge_weight.shape}:\\n', edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataset(n_samples=52537, n_nodes=5016, n_channels=1)\n"
     ]
    }
   ],
   "source": [
    "torch_dataset = tsl.data.SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      connectivity=connectivity,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=12,\n",
    "                                      window=12,\n",
    "                                      stride=1)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(\n",
      "  input=(x=[t=12, n=5016, f=1], edge_index=[2, e=1090660], edge_weight=[e=1090660]),\n",
      "  target=(y=[t=12, n=5016, f=1]),\n",
      "  has_mask=False\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sample = torch_dataset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = sample.input.x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 't n f', 'edge_index': '2 e', 'edge_weight': 'e', 'y': 't n f'}\n"
     ]
    }
   ],
   "source": [
    "print(sample.pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[target], batch_size=64)\n"
     ]
    }
   ],
   "source": [
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=37815, val_len=4191, test_len=10507, scalers=[target], batch_size=64)\n"
     ]
    }
   ],
   "source": [
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynGESNModel(input_size=input_size,\n",
    "                reservoir_size=100,\n",
    "                input_scaling=1.,\n",
    "                reservoir_layers=1,\n",
    "                leaking_rate=0.9,\n",
    "                spectral_radius=0.9,\n",
    "                density=0.5,\n",
    "                reservoir_activation='tanh',\n",
    "                alpha_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mgphy\\GitHub_scripts\\Koopman\\DynGESN_DMD.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mgphy/GitHub_scripts/Koopman/DynGESN_DMD.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(sample\u001b[39m.\u001b[39;49minput\u001b[39m.\u001b[39;49mx, sample\u001b[39m.\u001b[39;49minput\u001b[39m.\u001b[39;49medge_index, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\mgphy\\Anaconda3\\envs\\koopman\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mgphy\\GitHub_scripts\\Koopman\\models\\DynGraphESN.py:183\u001b[0m, in \u001b[0;36mDynGESNModel.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m    182\u001b[0m     num_nodes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m#x.shape[0]\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     _, edge_weight \u001b[39m=\u001b[39m normalize(edge_index, edge_weight)\n\u001b[0;32m    184\u001b[0m     col, row \u001b[39m=\u001b[39m edge_index\n\u001b[0;32m    185\u001b[0m     edge_index \u001b[39m=\u001b[39m SparseTensor(row\u001b[39m=\u001b[39mrow, col\u001b[39m=\u001b[39mcol, value\u001b[39m=\u001b[39medge_weight,\n\u001b[0;32m    186\u001b[0m                               sparse_sizes\u001b[39m=\u001b[39m(x\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m), x\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\mgphy\\GitHub_scripts\\Koopman\\models\\utils.py:222\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(edge_index, edge_weights, dim, num_nodes)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m edge_index, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    221\u001b[0m index \u001b[39m=\u001b[39m edge_index[dim]\n\u001b[1;32m--> 222\u001b[0m degree \u001b[39m=\u001b[39m weighted_degree(index, edge_weights, num_nodes\u001b[39m=\u001b[39;49mnum_nodes)\n\u001b[0;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m edge_index, edge_weights \u001b[39m/\u001b[39m degree[index]\n",
      "File \u001b[1;32mc:\\Users\\mgphy\\GitHub_scripts\\Koopman\\models\\utils.py:187\u001b[0m, in \u001b[0;36mweighted_degree\u001b[1;34m(index, weights, num_nodes)\u001b[0m\n\u001b[0;32m    184\u001b[0m         weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((index\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m),),\n\u001b[0;32m    185\u001b[0m                              device\u001b[39m=\u001b[39mindex\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint)\n\u001b[0;32m    186\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((N,\u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mweights\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mweights\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 187\u001b[0m     out\u001b[39m.\u001b[39;49mscatter_add_(\u001b[39m0\u001b[39;49m, index\u001b[39m.\u001b[39;49munsqueeze(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), weights)\n\u001b[0;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "model(sample.input.x, sample.input.edge_index, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.model(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
